# -*- coding: utf-8 -*-
"""Submission1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OTFqnIbb7F1J9Dh9CDNXji8fZ-Zy0fWO
"""

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

print(tf.__version__)

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# Ekstraksi File zip
import zipfile, os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/rockpaperscissors/rps-cv-images'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

os.listdir('/tmp/rockpaperscissors/rps-cv-images')

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.5,
    #zoom_range = 20,
    fill_mode = 'nearest'
)

test_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.5,
    #zoom_range = 20,
    fill_mode = 'nearest'
)

datagen = ImageDataGenerator(validation_split= 0.3, rescale=1./255)

train_generator = datagen.flow_from_directory(
  directory = base_dir,  # direktori data latih
  target_size=(100, 150),  
  batch_size= 8,
  subset = 'training',
  class_mode='categorical')
     
validation_generator = datagen.flow_from_directory(
  directory = base_dir,  # direktori data latih
  target_size=(100, 150),  
  batch_size= 8,
  subset = 'validation',
  class_mode='categorical')

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 150, 3)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(512, activation='relu'),
  tf.keras.layers.Dense(3, activation='softmax')
])

model.compile(loss='binary_crossentropy',
  optimizer=tf.optimizers.Adam(),
  metrics=['accuracy'])

model.fit(
  train_generator,
  steps_per_epoch=25,
  epochs=20,
  validation_data=validation_generator,
  validation_steps=5,
  verbose=2)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  #Predict Image
  path = fn
  img = image.load_img(path, target_size=(100, 150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  hasil = np.argmax(classes)

  print(fn)
  if hasil == 0:
    print('ini kertas')
  elif hasil == 1:
    print('ini batu')
  elif hasil == 2:
    print('ini gunting')